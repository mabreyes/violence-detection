{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, applications\n",
    "from tensorflow.keras.layers import LSTM, GRU, Bidirectional, TimeDistributed, Attention\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "@dataclass\n",
    "class FrameMetadata:\n",
    "    \"\"\"Dataclass to store metadata for each video frame\"\"\"\n",
    "    motion_intensity: float\n",
    "    scene_complexity: float\n",
    "    lighting_condition: str\n",
    "    timestamp: float\n",
    "    blur_factor: float\n",
    "    dominant_color: Tuple[float, float, float]\n",
    "\n",
    "class VideoFrameGenerator:\n",
    "    \"\"\"Class to generate sophisticated mock video frames\"\"\"\n",
    "    \n",
    "    def __init__(self, frame_size: int = 299):\n",
    "        self.frame_size = frame_size\n",
    "        self._supported_patterns = {\n",
    "            'violent': self._generate_violent_pattern,\n",
    "            'non_violent': self._generate_non_violent_pattern\n",
    "        }\n",
    "\n",
    "    def _apply_motion_blur(self, frame: np.ndarray, kernel_size: int) -> np.ndarray:\n",
    "        \"\"\"Apply sophisticated motion blur effect\"\"\"\n",
    "        kernel = np.zeros((kernel_size, kernel_size))\n",
    "        kernel[int((kernel_size-1)/2), :] = np.ones(kernel_size)\n",
    "        kernel = kernel / kernel_size\n",
    "        return cv2.filter2D(frame, -1, kernel)\n",
    "\n",
    "    def _generate_violent_pattern(self, frame_idx: int, num_frames: int) -> np.ndarray:\n",
    "        \"\"\"Generate complex violent patterns with temporal coherence\"\"\"\n",
    "        frame = np.zeros((self.frame_size, self.frame_size, 3))\n",
    "        \n",
    "        # Create dynamic patterns\n",
    "        t = frame_idx / num_frames\n",
    "        frequency = 5 + 3 * np.sin(2 * np.pi * t)\n",
    "        x, y = np.meshgrid(\n",
    "            np.linspace(0, frequency, self.frame_size),\n",
    "            np.linspace(0, frequency, self.frame_size)\n",
    "        )\n",
    "        \n",
    "        # Generate complex wave patterns\n",
    "        wave = np.sin(x) * np.cos(y) * np.sin(2 * np.pi * t)\n",
    "        frame[:,:,0] = np.clip(wave * 0.5 + 0.5, 0, 1)\n",
    "        \n",
    "        # Add geometric patterns\n",
    "        num_shapes = int(5 + 3 * np.sin(2 * np.pi * t))\n",
    "        for _ in range(num_shapes):\n",
    "            points = np.random.randint(0, self.frame_size, (np.random.randint(3, 7), 2))\n",
    "            cv2.fillPoly(frame, [points], (1, np.random.random() * 0.5, 0))\n",
    "        \n",
    "        return frame\n",
    "\n",
    "    def _generate_non_violent_pattern(self, frame_idx: int, num_frames: int) -> np.ndarray:\n",
    "        \"\"\"Generate complex non-violent patterns with smooth transitions\"\"\"\n",
    "        frame = np.zeros((self.frame_size, self.frame_size, 3))\n",
    "        \n",
    "        t = frame_idx / num_frames\n",
    "        x, y = np.meshgrid(\n",
    "            np.linspace(0, 1, self.frame_size),\n",
    "            np.linspace(0, 1, self.frame_size)\n",
    "        )\n",
    "        \n",
    "        # Create peaceful patterns\n",
    "        frame[:,:,1] = np.sin(3 * np.pi * x) * np.cos(3 * np.pi * y) * 0.5 + 0.5\n",
    "        frame[:,:,2] = np.cos(2 * np.pi * x * t) * np.sin(2 * np.pi * y * t) * 0.3 + 0.7\n",
    "        \n",
    "        return frame\n",
    "\n",
    "    def generate_sequence(self, num_frames: int, is_violent: bool = False) -> Tuple[np.ndarray, List[FrameMetadata]]:\n",
    "        \"\"\"Generate a sequence of frames with metadata\"\"\"\n",
    "        pattern_type = 'violent' if is_violent else 'non_violent'\n",
    "        frames = []\n",
    "        metadata = []\n",
    "        \n",
    "        for i in range(num_frames):\n",
    "            frame = self._supported_patterns[pattern_type](i, num_frames)\n",
    "            \n",
    "            # Apply sophisticated effects\n",
    "            if is_violent:\n",
    "                kernel_size = np.random.choice([3, 5, 7])\n",
    "                frame = self._apply_motion_blur(frame, kernel_size)\n",
    "            \n",
    "            frames.append(frame)\n",
    "            \n",
    "            # Generate detailed metadata\n",
    "            metadata.append(FrameMetadata(\n",
    "                motion_intensity=np.random.uniform(0.7, 1.0) if is_violent else np.random.uniform(0.1, 0.5),\n",
    "                scene_complexity=np.random.uniform(0.6, 1.0) if is_violent else np.random.uniform(0.2, 0.7),\n",
    "                lighting_condition=np.random.choice(['dark', 'bright', 'mixed']),\n",
    "                timestamp=i/num_frames,\n",
    "                blur_factor=np.random.uniform(0.5, 1.0) if is_violent else np.random.uniform(0.1, 0.4),\n",
    "                dominant_color=tuple(np.random.random(3))\n",
    "            ))\n",
    "        \n",
    "        return np.array(frames), metadata\n",
    "\n",
    "class ViolenceDetectionDataset:\n",
    "    \"\"\"Class to manage the violence detection dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, num_samples: int = 200, sequence_length: int = 45):\n",
    "        self.num_samples = num_samples\n",
    "        self.sequence_length = sequence_length\n",
    "        self.frame_generator = VideoFrameGenerator()\n",
    "        self.data = self._generate_dataset()\n",
    "    \n",
    "    def _generate_dataset(self) -> Dict:\n",
    "        \"\"\"Generate complete dataset with balanced classes\"\"\"\n",
    "        logger.info(\"Generating sophisticated mock dataset...\")\n",
    "        \n",
    "        X, y, metadata = [], [], []\n",
    "        \n",
    "        for is_violent in [True, False]:\n",
    "            for _ in range(self.num_samples // 2):\n",
    "                frames, frame_metadata = self.frame_generator.generate_sequence(\n",
    "                    self.sequence_length, is_violent\n",
    "                )\n",
    "                X.extend(frames)\n",
    "                y.extend([1 if is_violent else 0] * len(frames))\n",
    "                metadata.extend(frame_metadata)\n",
    "        \n",
    "        return {\n",
    "            'X': np.array(X),\n",
    "            'y': np.array(y),\n",
    "            'metadata': metadata\n",
    "        }\n",
    "    \n",
    "    def get_train_test_split(self, test_size: float = 0.2) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"Split dataset into training and testing sets\"\"\"\n",
    "        return train_test_split(\n",
    "            self.data['X'],\n",
    "            self.data['y'],\n",
    "            test_size=test_size,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "class ViolenceDetectionModel:\n",
    "    \"\"\"Advanced model for violence detection\"\"\"\n",
    "    \n",
    "    def __init__(self, input_shape: Tuple[int, int, int, int]):\n",
    "        self.input_shape = input_shape\n",
    "        self.model = self._build_model()\n",
    "    \n",
    "    def _build_model(self) -> models.Model:\n",
    "        \"\"\"Build sophisticated model architecture\"\"\"\n",
    "        # Base model - Inception V3\n",
    "        base_model = applications.InceptionV3(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=self.input_shape[2:]\n",
    "        )\n",
    "        \n",
    "        # Freeze early layers\n",
    "        for layer in base_model.layers[:249]:\n",
    "            layer.trainable = False\n",
    "        \n",
    "        # Build advanced architecture\n",
    "        input_layer = layers.Input(shape=self.input_shape[1:])\n",
    "        \n",
    "        x = TimeDistributed(base_model)(input_layer)\n",
    "        x = TimeDistributed(layers.GlobalAveragePooling2D())(x)\n",
    "        \n",
    "        # Multi-stream processing\n",
    "        lstm_stream = Bidirectional(LSTM(256, return_sequences=True))(x)\n",
    "        lstm_stream = Bidirectional(LSTM(128, return_sequences=True))(lstm_stream)\n",
    "        \n",
    "        gru_stream = Bidirectional(GRU(256, return_sequences=True))(x)\n",
    "        attention_layer = Attention()([gru_stream, gru_stream])\n",
    "        \n",
    "        merged = layers.Concatenate()([lstm_stream, attention_layer])\n",
    "        \n",
    "        x = layers.Dense(512, activation='relu')(merged)\n",
    "        x = layers.Dropout(0.5)(x)\n",
    "        x = layers.Dense(256, activation='relu')(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        \n",
    "        x = layers.GlobalAveragePooling1D()(x)\n",
    "        \n",
    "        main_output = layers.Dense(1, activation='sigmoid', name='main_output')(x)\n",
    "        aux_output = layers.Dense(3, activation='softmax', name='aux_output')(x)\n",
    "        \n",
    "        return models.Model(inputs=input_layer, outputs=[main_output, aux_output])\n",
    "    \n",
    "    def compile_model(self, learning_rate: float = 0.0001):\n",
    "        \"\"\"Compile model with custom settings\"\"\"\n",
    "        self.model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "            loss={\n",
    "                'main_output': 'binary_crossentropy',\n",
    "                'aux_output': 'sparse_categorical_crossentropy'\n",
    "            },\n",
    "            loss_weights={'main_output': 1.0, 'aux_output': 0.3},\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "    \n",
    "    def train(self, train_data: Dict, test_data: Dict, epochs: int = 20, batch_size: int = 16) -> Dict:\n",
    "        \"\"\"Train the model with advanced callbacks\"\"\"\n",
    "        callbacks = [\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_main_output_loss',\n",
    "                factor=0.5,\n",
    "                patience=3,\n",
    "                min_lr=1e-6\n",
    "            ),\n",
    "            tf.keras.callbacks.EarlyStopping(\n",
    "                monitor='val_main_output_loss',\n",
    "                patience=5,\n",
    "                restore_best_weights=True\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        return self.model.fit(\n",
    "            train_data['X'],\n",
    "            {'main_output': train_data['y'], 'aux_output': train_data['aux_y']},\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(\n",
    "                test_data['X'],\n",
    "                {'main_output': test_data['y'], 'aux_output': test_data['aux_y']}\n",
    "            ),\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "\n",
    "def main():\n",
    "    # Create dataset\n",
    "    dataset = ViolenceDetectionDataset(num_samples=200)\n",
    "    X_train, X_test, y_train, y_test = dataset.get_train_test_split()\n",
    "    \n",
    "    # Reshape data\n",
    "    seq_length = 45\n",
    "    X_train = X_train.reshape(-1, seq_length, 299, 299, 3)\n",
    "    X_test = X_test.reshape(-1, seq_length, 299, 299, 3)\n",
    "    y_train = y_train.reshape(-1, seq_length)\n",
    "    y_test = y_test.reshape(-1, seq_length)\n",
    "    \n",
    "    # Create auxiliary targets\n",
    "    y_aux_train = np.random.randint(0, 3, size=(y_train.shape[0], seq_length))\n",
    "    y_aux_test = np.random.randint(0, 3, size=(y_test.shape[0], seq_length))\n",
    "    \n",
    "    # Prepare data dictionaries\n",
    "    train_data = {'X': X_train, 'y': y_train, 'aux_y': y_aux_train}\n",
    "    test_data = {'X': X_test, 'y': y_test, 'aux_y': y_aux_test}\n",
    "    \n",
    "    # Create and train model\n",
    "    model = ViolenceDetectionModel(input_shape=X_train.shape)\n",
    "    model.compile_model()\n",
    "    \n",
    "    logger.info(\"Training advanced model...\")\n",
    "    history = model.train(train_data, test_data)\n",
    "    \n",
    "    # Visualize results\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Plot main task accuracy\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(history.history['main_output_accuracy'], label='Training')\n",
    "    plt.plot(history.history['val_main_output_accuracy'], label='Validation')\n",
    "    plt.title('Main Task Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot main task loss\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(history.history['main_output_loss'], label='Training')\n",
    "    plt.plot(history.history['val_main_output_loss'], label='Validation')\n",
    "    plt.title('Main Task Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot auxiliary task accuracy\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(history.history['aux_output_accuracy'], label='Training')\n",
    "    plt.plot(history.history['val_aux_output_accuracy'], label='Validation')\n",
    "    plt.title('Auxiliary Task Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
