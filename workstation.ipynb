{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Violence Detection Model Training Pipeline\n",
    "\n",
    "This notebook implements a sophisticated deep learning pipeline for violence detection in video sequences.\n",
    "It includes:\n",
    "\n",
    "- Data generation and preprocessing\n",
    "- Advanced model architecture with multi-stream processing\n",
    "- Training and evaluation workflow\n",
    "- Visualization of results\n",
    "\n",
    "Key Components:\n",
    "\n",
    "1. Data Management\n",
    "   - VideoFrameGenerator: Generates synthetic video frames with metadata\n",
    "   - ViolenceDetectionDataset: Manages dataset creation and splitting\n",
    "   - FrameMetadata: Stores per-frame metadata\n",
    "\n",
    "2. Model Architecture  \n",
    "   - Based on InceptionV3 backbone\n",
    "   - Bidirectional LSTM and GRU streams\n",
    "   - Attention mechanism\n",
    "   - Multi-task learning with main and auxiliary outputs\n",
    "\n",
    "3. Training Pipeline\n",
    "   - Custom learning rate scheduling\n",
    "   - Early stopping\n",
    "   - Performance visualization\n",
    "   - Comprehensive logging\n",
    "\n",
    "Usage:\n",
    "    Run all cells to:\n",
    "    1. Generate synthetic training data\n",
    "    2. Build and compile model\n",
    "    3. Train model with visualization\n",
    "    4. Evaluate performance\n",
    "\n",
    "Author: Marc Reyes\n",
    "\"\"\"\n",
    "\n",
    "# Import required libraries\n",
    "import logging\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import applications, layers, models\n",
    "from tensorflow.keras.layers import GRU, LSTM, Attention, Bidirectional, TimeDistributed\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class FrameMetadata:\n",
    "    \"\"\"\n",
    "    Dataclass to store metadata for each video frame.\n",
    "\n",
    "    Attributes:\n",
    "        motion_intensity (float): Measure of motion between consecutive frames (0-1)\n",
    "        scene_complexity (float): Complexity score of the frame content (0-1)\n",
    "        lighting_condition (str): Lighting description ('dark', 'bright', 'mixed')\n",
    "        timestamp (float): Normalized timestamp in the sequence (0-1)\n",
    "        blur_factor (float): Amount of motion blur in the frame (0-1)\n",
    "        dominant_color (Tuple[float, float, float]): RGB values of dominant color\n",
    "    \"\"\"\n",
    "\n",
    "    motion_intensity: float\n",
    "    scene_complexity: float\n",
    "    lighting_condition: str\n",
    "    timestamp: float\n",
    "    blur_factor: float\n",
    "    dominant_color: Tuple[float, float, float]\n",
    "\n",
    "\n",
    "class VideoFrameGenerator:\n",
    "    \"\"\"\n",
    "    Class to generate sophisticated mock video frames.\n",
    "\n",
    "    This class creates synthetic video frames with different patterns for violent\n",
    "    and non-violent content, including motion effects and metadata generation.\n",
    "\n",
    "    Args:\n",
    "        frame_size (int): Size of generated frames (width=height)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, frame_size: int = 299):\n",
    "        self.frame_size = frame_size\n",
    "        self._supported_patterns = {\n",
    "            \"violent\": self._generate_violent_pattern,\n",
    "            \"non_violent\": self._generate_non_violent_pattern,\n",
    "        }\n",
    "\n",
    "    def _apply_motion_blur(self, frame: np.ndarray, kernel_size: int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Apply sophisticated motion blur effect to frame.\n",
    "\n",
    "        Args:\n",
    "            frame (np.ndarray): Input frame\n",
    "            kernel_size (int): Size of motion blur kernel\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Blurred frame\n",
    "        \"\"\"\n",
    "        kernel = np.zeros((kernel_size, kernel_size))\n",
    "        kernel[int((kernel_size - 1) / 2), :] = np.ones(kernel_size)\n",
    "        kernel = kernel / kernel_size\n",
    "        return cv2.filter2D(frame, -1, kernel)\n",
    "\n",
    "    def _generate_violent_pattern(self, frame_idx: int, num_frames: int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate complex violent patterns with temporal coherence.\n",
    "\n",
    "        Creates frames with rapid motion, sharp transitions and geometric shapes\n",
    "        characteristic of violent scenes.\n",
    "\n",
    "        Args:\n",
    "            frame_idx (int): Current frame index\n",
    "            num_frames (int): Total number of frames\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Generated frame with violent patterns\n",
    "        \"\"\"\n",
    "        frame = np.zeros((self.frame_size, self.frame_size, 3))\n",
    "\n",
    "        t = frame_idx / num_frames\n",
    "        frequency = 5 + 3 * np.sin(2 * np.pi * t)\n",
    "        x, y = np.meshgrid(\n",
    "            np.linspace(0, frequency, self.frame_size),\n",
    "            np.linspace(0, frequency, self.frame_size),\n",
    "        )\n",
    "\n",
    "        wave = np.sin(x) * np.cos(y) * np.sin(2 * np.pi * t)\n",
    "        frame[:, :, 0] = np.clip(wave * 0.5 + 0.5, 0, 1)\n",
    "\n",
    "        num_shapes = int(5 + 3 * np.sin(2 * np.pi * t))\n",
    "        for _ in range(num_shapes):\n",
    "            points = np.random.randint(0, self.frame_size, (np.random.randint(3, 7), 2))\n",
    "            cv2.fillPoly(frame, [points], (1, np.random.random() * 0.5, 0))\n",
    "\n",
    "        return frame\n",
    "\n",
    "    def _generate_non_violent_pattern(\n",
    "        self, frame_idx: int, num_frames: int\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate complex non-violent patterns with smooth transitions.\n",
    "\n",
    "        Creates frames with gentle gradients and smooth color transitions\n",
    "        characteristic of non-violent scenes.\n",
    "\n",
    "        Args:\n",
    "            frame_idx (int): Current frame index\n",
    "            num_frames (int): Total number of frames\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Generated frame with non-violent patterns\n",
    "        \"\"\"\n",
    "        frame = np.zeros((self.frame_size, self.frame_size, 3))\n",
    "\n",
    "        t = frame_idx / num_frames\n",
    "        x, y = np.meshgrid(\n",
    "            np.linspace(0, 1, self.frame_size), np.linspace(0, 1, self.frame_size)\n",
    "        )\n",
    "\n",
    "        frame[:, :, 1] = np.sin(3 * np.pi * x) * np.cos(3 * np.pi * y) * 0.5 + 0.5\n",
    "        frame[:, :, 2] = (\n",
    "            np.cos(2 * np.pi * x * t) * np.sin(2 * np.pi * y * t) * 0.3 + 0.7\n",
    "        )\n",
    "\n",
    "        return frame\n",
    "\n",
    "    def generate_sequence(\n",
    "        self, num_frames: int, is_violent: bool = False\n",
    "    ) -> Tuple[np.ndarray, List[FrameMetadata]]:\n",
    "        \"\"\"\n",
    "        Generate a sequence of frames with metadata.\n",
    "\n",
    "        Args:\n",
    "            num_frames (int): Number of frames to generate\n",
    "            is_violent (bool): Whether to generate violent or non-violent sequence\n",
    "\n",
    "        Returns:\n",
    "            Tuple[np.ndarray, List[FrameMetadata]]: Generated frames and metadata\n",
    "        \"\"\"\n",
    "        pattern_type = \"violent\" if is_violent else \"non_violent\"\n",
    "        frames = []\n",
    "        metadata = []\n",
    "\n",
    "        for i in range(num_frames):\n",
    "            frame = self._supported_patterns[pattern_type](i, num_frames)\n",
    "\n",
    "            if is_violent:\n",
    "                kernel_size = np.random.choice([3, 5, 7])\n",
    "                frame = self._apply_motion_blur(frame, kernel_size)\n",
    "\n",
    "            frames.append(frame)\n",
    "\n",
    "            metadata.append(\n",
    "                FrameMetadata(\n",
    "                    motion_intensity=np.random.uniform(0.7, 1.0)\n",
    "                    if is_violent\n",
    "                    else np.random.uniform(0.1, 0.5),\n",
    "                    scene_complexity=np.random.uniform(0.6, 1.0)\n",
    "                    if is_violent\n",
    "                    else np.random.uniform(0.2, 0.7),\n",
    "                    lighting_condition=np.random.choice([\"dark\", \"bright\", \"mixed\"]),\n",
    "                    timestamp=i / num_frames,\n",
    "                    blur_factor=np.random.uniform(0.5, 1.0)\n",
    "                    if is_violent\n",
    "                    else np.random.uniform(0.1, 0.4),\n",
    "                    dominant_color=tuple(np.random.random(3)),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return np.array(frames), metadata\n",
    "\n",
    "\n",
    "class ViolenceDetectionDataset:\n",
    "    \"\"\"\n",
    "    Class to manage the violence detection dataset.\n",
    "\n",
    "    Handles dataset generation, storage and train/test splitting.\n",
    "\n",
    "    Args:\n",
    "        num_samples (int): Number of sequences to generate\n",
    "        sequence_length (int): Length of each sequence\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_samples: int = 200, sequence_length: int = 45):\n",
    "        self.num_samples = num_samples\n",
    "        self.sequence_length = sequence_length\n",
    "        self.frame_generator = VideoFrameGenerator()\n",
    "        self.data = self._generate_dataset()\n",
    "\n",
    "    def _generate_dataset(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Generate complete dataset with balanced classes.\n",
    "\n",
    "        Returns:\n",
    "            Dict: Dataset containing features, labels and metadata\n",
    "        \"\"\"\n",
    "        logger.info(\"Generating sophisticated mock dataset...\")\n",
    "\n",
    "        X, y, metadata = [], [], []\n",
    "\n",
    "        for is_violent in [True, False]:\n",
    "            for _ in range(self.num_samples // 2):\n",
    "                frames, frame_metadata = self.frame_generator.generate_sequence(\n",
    "                    self.sequence_length, is_violent\n",
    "                )\n",
    "                X.extend(frames)\n",
    "                y.extend([1 if is_violent else 0] * len(frames))\n",
    "                metadata.extend(frame_metadata)\n",
    "\n",
    "        return {\"X\": np.array(X), \"y\": np.array(y), \"metadata\": metadata}\n",
    "\n",
    "    def get_train_test_split(\n",
    "        self, test_size: float = 0.2\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Split dataset into training and testing sets.\n",
    "\n",
    "        Args:\n",
    "            test_size (float): Proportion of data for testing\n",
    "\n",
    "        Returns:\n",
    "            Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]: Train/test split arrays\n",
    "        \"\"\"\n",
    "        return train_test_split(\n",
    "            self.data[\"X\"], self.data[\"y\"], test_size=test_size, random_state=42\n",
    "        )\n",
    "\n",
    "\n",
    "class ViolenceDetectionModel:\n",
    "    \"\"\"\n",
    "    Advanced model for violence detection.\n",
    "\n",
    "    Implements a sophisticated neural network architecture combining CNN, RNN\n",
    "    and attention mechanisms for video-based violence detection.\n",
    "\n",
    "    Args:\n",
    "        input_shape (Tuple[int, int, int, int]): Shape of input tensors\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_shape: Tuple[int, int, int, int]):\n",
    "        self.input_shape = input_shape\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _build_model(self) -> models.Model:\n",
    "        \"\"\"\n",
    "        Build sophisticated model architecture.\n",
    "\n",
    "        Returns:\n",
    "            models.Model: Compiled Keras model\n",
    "        \"\"\"\n",
    "        base_model = applications.InceptionV3(\n",
    "            weights=\"imagenet\", include_top=False, input_shape=self.input_shape[2:]\n",
    "        )\n",
    "\n",
    "        for layer in base_model.layers[:249]:\n",
    "            layer.trainable = False\n",
    "\n",
    "        input_layer = layers.Input(shape=self.input_shape[1:])\n",
    "\n",
    "        x = TimeDistributed(base_model)(input_layer)\n",
    "        x = TimeDistributed(layers.GlobalAveragePooling2D())(x)\n",
    "\n",
    "        lstm_stream = Bidirectional(LSTM(256, return_sequences=True))(x)\n",
    "        lstm_stream = Bidirectional(LSTM(128, return_sequences=True))(lstm_stream)\n",
    "\n",
    "        gru_stream = Bidirectional(GRU(256, return_sequences=True))(x)\n",
    "        attention_layer = Attention()([gru_stream, gru_stream])\n",
    "\n",
    "        merged = layers.Concatenate()([lstm_stream, attention_layer])\n",
    "\n",
    "        x = layers.Dense(512, activation=\"relu\")(merged)\n",
    "        x = layers.Dropout(0.5)(x)\n",
    "        x = layers.Dense(256, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "\n",
    "        x = layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "        main_output = layers.Dense(1, activation=\"sigmoid\", name=\"main_output\")(x)\n",
    "        aux_output = layers.Dense(3, activation=\"softmax\", name=\"aux_output\")(x)\n",
    "\n",
    "        return models.Model(inputs=input_layer, outputs=[main_output, aux_output])\n",
    "\n",
    "    def compile_model(self, learning_rate: float = 0.0001):\n",
    "        \"\"\"\n",
    "        Compile model with custom settings.\n",
    "\n",
    "        Args:\n",
    "            learning_rate (float): Initial learning rate\n",
    "        \"\"\"\n",
    "        self.model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "            loss={\n",
    "                \"main_output\": \"binary_crossentropy\",\n",
    "                \"aux_output\": \"sparse_categorical_crossentropy\",\n",
    "            },\n",
    "            loss_weights={\"main_output\": 1.0, \"aux_output\": 0.3},\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "\n",
    "    def train(\n",
    "        self, train_data: Dict, test_data: Dict, epochs: int = 20, batch_size: int = 16\n",
    "    ) -> Dict:\n",
    "        \"\"\"\n",
    "        Train the model with advanced callbacks.\n",
    "\n",
    "        Args:\n",
    "            train_data (Dict): Training data dictionary\n",
    "            test_data (Dict): Testing data dictionary\n",
    "            epochs (int): Number of training epochs\n",
    "            batch_size (int): Batch size for training\n",
    "\n",
    "        Returns:\n",
    "            Dict: Training history\n",
    "        \"\"\"\n",
    "        callbacks = [\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor=\"val_main_output_loss\", factor=0.5, patience=3, min_lr=1e-6\n",
    "            ),\n",
    "            tf.keras.callbacks.EarlyStopping(\n",
    "                monitor=\"val_main_output_loss\", patience=5, restore_best_weights=True\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        return self.model.fit(\n",
    "            train_data[\"X\"],\n",
    "            {\"main_output\": train_data[\"y\"], \"aux_output\": train_data[\"aux_y\"]},\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(\n",
    "                test_data[\"X\"],\n",
    "                {\"main_output\": test_data[\"y\"], \"aux_output\": test_data[\"aux_y\"]},\n",
    "            ),\n",
    "            callbacks=callbacks,\n",
    "        )\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main execution function.\n",
    "\n",
    "    Orchestrates the complete training pipeline:\n",
    "    1. Dataset creation and preprocessing\n",
    "    2. Model initialization and training\n",
    "    3. Results visualization\n",
    "    \"\"\"\n",
    "    # Create dataset\n",
    "    dataset = ViolenceDetectionDataset(num_samples=200)\n",
    "    X_train, X_test, y_train, y_test = dataset.get_train_test_split()\n",
    "\n",
    "    # Reshape data\n",
    "    seq_length = 45\n",
    "    X_train = X_train.reshape(-1, seq_length, 299, 299, 3)\n",
    "    X_test = X_test.reshape(-1, seq_length, 299, 299, 3)\n",
    "    y_train = y_train.reshape(-1, seq_length)\n",
    "    y_test = y_test.reshape(-1, seq_length)\n",
    "\n",
    "    # Create auxiliary targets\n",
    "    y_aux_train = np.random.randint(0, 3, size=(y_train.shape[0], seq_length))\n",
    "    y_aux_test = np.random.randint(0, 3, size=(y_test.shape[0], seq_length))\n",
    "\n",
    "    # Prepare data dictionaries\n",
    "    train_data = {\"X\": X_train, \"y\": y_train, \"aux_y\": y_aux_train}\n",
    "    test_data = {\"X\": X_test, \"y\": y_test, \"aux_y\": y_aux_test}\n",
    "\n",
    "    # Create and train model\n",
    "    model = ViolenceDetectionModel(input_shape=X_train.shape)\n",
    "    model.compile_model()\n",
    "\n",
    "    logger.info(\"Training advanced model...\")\n",
    "    history = model.train(train_data, test_data)\n",
    "\n",
    "    # Visualize results\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(history.history[\"main_output_accuracy\"], label=\"Training\")\n",
    "    plt.plot(history.history[\"val_main_output_accuracy\"], label=\"Validation\")\n",
    "    plt.title(\"Main Task Accuracy\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(history.history[\"main_output_loss\"], label=\"Training\")\n",
    "    plt.plot(history.history[\"val_main_output_loss\"], label=\"Validation\")\n",
    "    plt.title(\"Main Task Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(history.history[\"aux_output_accuracy\"], label=\"Training\")\n",
    "    plt.plot(history.history[\"val_aux_output_accuracy\"], label=\"Validation\")\n",
    "    plt.title(\"Auxiliary Task Accuracy\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
